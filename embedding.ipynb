{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sentences\n",
    "sent = ['the glass of milk',\n",
    "        'the glass of juice',\n",
    "        'the cup of tea',\n",
    "        'I am a good boy',\n",
    "        'I am a good developer',\n",
    "        'understand the meaning of words',\n",
    "        'my name is rondon',\n",
    "        'my life is very good',\n",
    "        'my life is bad',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'my name is rondon',\n",
       " 'my life is very good',\n",
       " 'my life is bad']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the vocabulary size\n",
    "\n",
    "vocab_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[914, 7786, 7674, 3473],\n",
       " [914, 7786, 7674, 5858],\n",
       " [914, 5780, 7674, 7146],\n",
       " [4639, 42, 6084, 8211, 3672],\n",
       " [4639, 42, 6084, 8211, 7236],\n",
       " [5761, 914, 3651, 7674, 2477],\n",
       " [3402, 1857, 4223, 2162],\n",
       " [3402, 6721, 4223, 3133, 8211],\n",
       " [3402, 6721, 4223, 399]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### One Hot Representation\n",
    "one_hot_repr = []\n",
    "\n",
    "for words in sent:\n",
    "    one_hot_repr.append(one_hot(words, vocab_size))\n",
    "\n",
    "one_hot_repr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike traditional one-hot encoding, which transforms each word into a high-dimensional sparse vector with a vocabulary-sized dimension (e.g., 10,000) and only a single 1 among zeros, the tensorflow.keras.preprocessing.text.one_hot() method provides a more compact representation.\n",
    "Instead of generating the full binary vector, it returns the index position where the 1 would have been, effectively mapping each word to an integer value based on a hashing function. This significantly reduces memory usage and avoids the inefficiency of handling large sparse matrices during preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main limitations of this method, when preparing text data for neural networks, is that each sentence may have a different length. This variability must be addressed, as models require inputs of uniform size. Without resolving this issue, it is not possible to train any standard neural network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0  914 7786 7674 3473]\n",
      " [   0    0    0    0  914 7786 7674 5858]\n",
      " [   0    0    0    0  914 5780 7674 7146]\n",
      " [   0    0    0 4639   42 6084 8211 3672]\n",
      " [   0    0    0 4639   42 6084 8211 7236]\n",
      " [   0    0    0 5761  914 3651 7674 2477]\n",
      " [   0    0    0    0 3402 1857 4223 2162]\n",
      " [   0    0    0 3402 6721 4223 3133 8211]\n",
      " [   0    0    0    0 3402 6721 4223  399]]\n"
     ]
    }
   ],
   "source": [
    "## Word Embedding Representation\n",
    "\n",
    "sent_length = 8\n",
    "embedded_docs = pad_sequences(one_hot_repr, padding='pre', maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,  914, 7786, 7674, 3473],\n",
       "       [   0,    0,    0,    0,  914, 7786, 7674, 5858],\n",
       "       [   0,    0,    0,    0,  914, 5780, 7674, 7146],\n",
       "       [   0,    0,    0, 4639,   42, 6084, 8211, 3672],\n",
       "       [   0,    0,    0, 4639,   42, 6084, 8211, 7236],\n",
       "       [   0,    0,    0, 5761,  914, 3651, 7674, 2477],\n",
       "       [   0,    0,    0,    0, 3402, 1857, 4223, 2162],\n",
       "       [   0,    0,    0, 3402, 6721, 4223, 3133, 8211],\n",
       "       [   0,    0,    0,    0, 3402, 6721, 4223,  399]], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address this issue, the pad_sequences method was used to standardize the length of all input sentences. This method adds zeros at the beginning of each sequence (pre-padding) based on a predefined maxlen parameter, ensuring that all input sequences have the same length and can be properly processed by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature representation\n",
    "\n",
    "dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rondon\\Desktop\\1. Python Starter\\16.krish_IA_Udemy\\04.02.deep_learning_4_nlp\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, dim, input_length=sent_length))\n",
    "model.compile('adam', 'mse')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **Initialization**:\n",
    "   - When it creates an Embedding layer with `Embedding(vocab_size, dim)`, it creates a weight matrix of size (vocab_size × dim)\n",
    "   - For example with vocab_size=10000 and dim=10, it creates a matrix of size 10000×10\n",
    "   - This matrix is initialized with random values (usually small random numbers)\n",
    "\n",
    "2. **Lookup Operation**:\n",
    "   - When input a word index (like 7786 for \"glass\"), the Embedding layer performs a lookup operation\n",
    "   - It's like a dictionary lookup where:\n",
    "     - The word index is the key\n",
    "     - The corresponding row in the weight matrix is the value\n",
    "   - For example, if input index 7786, it returns row 7786 from the weight matrix\n",
    "\n",
    "3. **Mathematical Representation**:\n",
    "   - The operation is essentially a matrix multiplication with a one-hot vector\n",
    "   - If we represent the word index as a one-hot vector (all zeros except a 1 at the word's position)\n",
    "   - The embedding operation is: `embedding_vector = one_hot_vector × weight_matrix`\n",
    "   - This is equivalent to selecting the corresponding row from the weight matrix\n",
    "\n",
    "4. **Learning Process**:\n",
    "   - During training, the weights in this matrix are updated using backpropagation\n",
    "   - The model learns to place similar words closer together in this vector space\n",
    "   - Words that appear in similar contexts will have similar vector representations\n",
    "\n",
    "5. **Efficiency**:\n",
    "   - This is much more efficient than traditional one-hot encoding\n",
    "   - Instead of having a vector of size vocab_size (e.g., 10000) with mostly zeros\n",
    "   - We get a dense vector of size dim (e.g., 10) with meaningful values\n",
    "\n",
    "6. **Semantic Relationships**:\n",
    "   - The model learns to place words with similar meanings close to each other in this vector space\n",
    "   - For example, \"king\" and \"queen\" might have similar vectors\n",
    "   - The difference between their vectors might represent the concept of gender\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.00583773,  0.02295682,  0.04650483, -0.02558252,\n",
       "         -0.03492404, -0.04526548,  0.03072326,  0.02082846,\n",
       "          0.02799947, -0.02984726],\n",
       "        [-0.03549889, -0.01597271,  0.01658494, -0.03778584,\n",
       "          0.00234162,  0.03394393,  0.04135187,  0.04740966,\n",
       "         -0.04382951, -0.00191938],\n",
       "        [ 0.03295279, -0.02001818, -0.00102039,  0.02780496,\n",
       "          0.04788676,  0.0123247 , -0.02243761,  0.04234291,\n",
       "          0.04929156,  0.01513654],\n",
       "        [ 0.03698624,  0.04046122, -0.00344026, -0.00572783,\n",
       "          0.04678627, -0.00649003,  0.03851301,  0.01929659,\n",
       "          0.01283241,  0.01507486]],\n",
       "\n",
       "       [[ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.00583773,  0.02295682,  0.04650483, -0.02558252,\n",
       "         -0.03492404, -0.04526548,  0.03072326,  0.02082846,\n",
       "          0.02799947, -0.02984726],\n",
       "        [-0.03549889, -0.01597271,  0.01658494, -0.03778584,\n",
       "          0.00234162,  0.03394393,  0.04135187,  0.04740966,\n",
       "         -0.04382951, -0.00191938],\n",
       "        [ 0.03295279, -0.02001818, -0.00102039,  0.02780496,\n",
       "          0.04788676,  0.0123247 , -0.02243761,  0.04234291,\n",
       "          0.04929156,  0.01513654],\n",
       "        [-0.01626902, -0.00680212, -0.04096749, -0.00117356,\n",
       "         -0.02622323,  0.03277816,  0.03075283, -0.0022682 ,\n",
       "          0.03763707,  0.03382589]],\n",
       "\n",
       "       [[ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.00583773,  0.02295682,  0.04650483, -0.02558252,\n",
       "         -0.03492404, -0.04526548,  0.03072326,  0.02082846,\n",
       "          0.02799947, -0.02984726],\n",
       "        [-0.0161558 , -0.02386168,  0.04165569, -0.04577507,\n",
       "          0.01438714, -0.00450184, -0.00674319,  0.04464174,\n",
       "         -0.02348923, -0.00573047],\n",
       "        [ 0.03295279, -0.02001818, -0.00102039,  0.02780496,\n",
       "          0.04788676,  0.0123247 , -0.02243761,  0.04234291,\n",
       "          0.04929156,  0.01513654],\n",
       "        [-0.04024969,  0.04603526,  0.01194245, -0.00590371,\n",
       "          0.02812428, -0.01494404, -0.01028421,  0.03858433,\n",
       "          0.01588852, -0.02905314]],\n",
       "\n",
       "       [[ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01894009,  0.01210842, -0.0343999 ,  0.0230468 ,\n",
       "          0.00013862, -0.00903112,  0.00617213, -0.04129148,\n",
       "          0.00600412, -0.03766208],\n",
       "        [-0.01604769,  0.02331198,  0.01397138, -0.03071735,\n",
       "         -0.03918431, -0.0235683 ,  0.02134731, -0.04365282,\n",
       "         -0.01233155, -0.0233979 ],\n",
       "        [-0.0286251 , -0.00423638,  0.04697273, -0.0074445 ,\n",
       "         -0.04833965, -0.04921202,  0.03438291,  0.01223511,\n",
       "          0.01170548,  0.04157961],\n",
       "        [-0.03427044,  0.01450456, -0.03063886, -0.02702665,\n",
       "          0.03198786,  0.01005174, -0.0288013 ,  0.01443552,\n",
       "         -0.04949336, -0.02500507],\n",
       "        [ 0.01384019,  0.03065247, -0.02544501,  0.00926097,\n",
       "         -0.0170787 , -0.02897665,  0.03661919,  0.01401946,\n",
       "         -0.01066735,  0.03173137]],\n",
       "\n",
       "       [[ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01894009,  0.01210842, -0.0343999 ,  0.0230468 ,\n",
       "          0.00013862, -0.00903112,  0.00617213, -0.04129148,\n",
       "          0.00600412, -0.03766208],\n",
       "        [-0.01604769,  0.02331198,  0.01397138, -0.03071735,\n",
       "         -0.03918431, -0.0235683 ,  0.02134731, -0.04365282,\n",
       "         -0.01233155, -0.0233979 ],\n",
       "        [-0.0286251 , -0.00423638,  0.04697273, -0.0074445 ,\n",
       "         -0.04833965, -0.04921202,  0.03438291,  0.01223511,\n",
       "          0.01170548,  0.04157961],\n",
       "        [-0.03427044,  0.01450456, -0.03063886, -0.02702665,\n",
       "          0.03198786,  0.01005174, -0.0288013 ,  0.01443552,\n",
       "         -0.04949336, -0.02500507],\n",
       "        [-0.04039573,  0.00824094, -0.01491664,  0.00282953,\n",
       "         -0.00507243, -0.00430037,  0.00564098, -0.01042645,\n",
       "         -0.03707385,  0.03356325]],\n",
       "\n",
       "       [[ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [-0.0454543 , -0.02847662,  0.00515878, -0.03359061,\n",
       "          0.0121058 ,  0.03490475,  0.01712363,  0.00252729,\n",
       "          0.03636298,  0.0247546 ],\n",
       "        [ 0.00583773,  0.02295682,  0.04650483, -0.02558252,\n",
       "         -0.03492404, -0.04526548,  0.03072326,  0.02082846,\n",
       "          0.02799947, -0.02984726],\n",
       "        [-0.03682175, -0.02088085, -0.01820172,  0.0311909 ,\n",
       "          0.01574067, -0.02210792,  0.01919358,  0.01606527,\n",
       "         -0.04315868,  0.00687081],\n",
       "        [ 0.03295279, -0.02001818, -0.00102039,  0.02780496,\n",
       "          0.04788676,  0.0123247 , -0.02243761,  0.04234291,\n",
       "          0.04929156,  0.01513654],\n",
       "        [ 0.04126069,  0.03511479,  0.0046289 ,  0.01019833,\n",
       "          0.02634634, -0.00484676, -0.04976224,  0.00330751,\n",
       "          0.04428467,  0.0326747 ]],\n",
       "\n",
       "       [[ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [-0.01702799,  0.01397773,  0.04889755, -0.00069146,\n",
       "         -0.03565406,  0.0399527 , -0.01826081, -0.01238006,\n",
       "         -0.03423468, -0.00598871],\n",
       "        [ 0.04107067, -0.00569187, -0.04484442,  0.04099022,\n",
       "          0.0105552 , -0.04550273, -0.02571477,  0.00796695,\n",
       "         -0.00198854,  0.0401875 ],\n",
       "        [-0.03492697,  0.00772501, -0.01100378, -0.00964422,\n",
       "         -0.00770386,  0.01824956, -0.01446151,  0.03433056,\n",
       "         -0.02568345,  0.0238697 ],\n",
       "        [-0.02139905,  0.0134601 , -0.00719593,  0.02407407,\n",
       "         -0.02338067,  0.03192637, -0.03868013, -0.04323422,\n",
       "          0.02976802,  0.04051281]],\n",
       "\n",
       "       [[ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [-0.01702799,  0.01397773,  0.04889755, -0.00069146,\n",
       "         -0.03565406,  0.0399527 , -0.01826081, -0.01238006,\n",
       "         -0.03423468, -0.00598871],\n",
       "        [-0.00422987, -0.00595993, -0.03379869, -0.02556747,\n",
       "         -0.02625986, -0.0002621 , -0.00477709, -0.04162753,\n",
       "         -0.03041824, -0.01498242],\n",
       "        [-0.03492697,  0.00772501, -0.01100378, -0.00964422,\n",
       "         -0.00770386,  0.01824956, -0.01446151,  0.03433056,\n",
       "         -0.02568345,  0.0238697 ],\n",
       "        [ 0.0158678 , -0.03851581, -0.00108532,  0.03194786,\n",
       "         -0.03503444, -0.04503381,  0.03913077,  0.03554939,\n",
       "          0.03052657, -0.01131903],\n",
       "        [-0.03427044,  0.01450456, -0.03063886, -0.02702665,\n",
       "          0.03198786,  0.01005174, -0.0288013 ,  0.01443552,\n",
       "         -0.04949336, -0.02500507]],\n",
       "\n",
       "       [[ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [-0.01702799,  0.01397773,  0.04889755, -0.00069146,\n",
       "         -0.03565406,  0.0399527 , -0.01826081, -0.01238006,\n",
       "         -0.03423468, -0.00598871],\n",
       "        [-0.00422987, -0.00595993, -0.03379869, -0.02556747,\n",
       "         -0.02625986, -0.0002621 , -0.00477709, -0.04162753,\n",
       "         -0.03041824, -0.01498242],\n",
       "        [-0.03492697,  0.00772501, -0.01100378, -0.00964422,\n",
       "         -0.00770386,  0.01824956, -0.01446151,  0.03433056,\n",
       "         -0.02568345,  0.0238697 ],\n",
       "        [ 0.02225066,  0.0235679 , -0.01394238, -0.0321209 ,\n",
       "          0.02432375, -0.03652816,  0.00110252,  0.0453746 ,\n",
       "          0.01036442, -0.03219422]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,  914, 7786, 7674, 3473], dtype=int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.01382059,  0.01172507, -0.04027963,  0.03795722,\n",
       "         -0.02197634, -0.01471256,  0.04129604,  0.00802499,\n",
       "          0.0404079 ,  0.03234955],\n",
       "        [ 0.00583773,  0.02295682,  0.04650483, -0.02558252,\n",
       "         -0.03492404, -0.04526548,  0.03072326,  0.02082846,\n",
       "          0.02799947, -0.02984726],\n",
       "        [-0.03549889, -0.01597271,  0.01658494, -0.03778584,\n",
       "          0.00234162,  0.03394393,  0.04135187,  0.04740966,\n",
       "         -0.04382951, -0.00191938],\n",
       "        [ 0.03295279, -0.02001818, -0.00102039,  0.02780496,\n",
       "          0.04788676,  0.0123247 , -0.02243761,  0.04234291,\n",
       "          0.04929156,  0.01513654],\n",
       "        [ 0.03698624,  0.04046122, -0.00344026, -0.00572783,\n",
       "          0.04678627, -0.00649003,  0.03851301,  0.01929659,\n",
       "          0.01283241,  0.01507486]]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 8, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs[0].reshape(1, -1)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **Input Processing**:\n",
    "   - The model starts with raw text sentences\n",
    "   - Each word is converted to a unique integer using `one_hot()` function\n",
    "   - The sentences are padded to have the same length (8 words) using `pad_sequences()`\n",
    "\n",
    "2. **Embedding Layer**:\n",
    "   - The `Embedding` layer takes three main parameters:\n",
    "     - `vocab_size`: 10000 (total number of unique words)\n",
    "     - `dim`: 10 (size of the embedding vector for each word)\n",
    "     - `input_length`: 8 (length of each padded sequence)\n",
    "\n",
    "3. **Transformation Process**:\n",
    "   - Each word (represented as an integer) is mapped to a 10-dimensional vector\n",
    "   - For example, if we have the word \"glass\" with index 7786, it gets transformed into a vector of 10 numbers\n",
    "   - These vectors are learned during training to capture semantic relationships between words\n",
    "\n",
    "4. **Output**:\n",
    "   - The model outputs a 3D tensor with shape (number_of_sentences, sequence_length, embedding_dimension)\n",
    "   - In your case, it's (9, 8, 10) - 9 sentences, each with 8 words, and each word represented by 10 numbers\n",
    "\n",
    "5. **What's Special**:\n",
    "   - Unlike one-hot encoding which creates sparse vectors (mostly zeros), embeddings create dense vectors\n",
    "   - Words with similar meanings will have similar vector representations\n",
    "   - The model learns these representations during training\n",
    "\n",
    "For example, in your output:\n",
    "- The first sentence \"the glass of milk\" was transformed from integers [914, 7786, 7674, 3473] into 10-dimensional vectors\n",
    "- Each word now has a dense representation that captures its meaning in the context of the sentence\n",
    "\n",
    "This is much more efficient than one-hot encoding and allows the model to learn meaningful relationships between words. The embedding layer essentially creates a lookup table where each word index maps to a learned vector representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **One-Hot Vector Representation**:\n",
    "   - Considering have a vocabulary of 3 words: [\"cat\", \"dog\", \"bird\"]\n",
    "   - Each word is represented as a one-hot vector:\n",
    "     ```\n",
    "     cat:  [1, 0, 0]\n",
    "     dog:  [0, 1, 0]\n",
    "     bird: [0, 0, 1]\n",
    "     ```\n",
    "\n",
    "2. **Embedding Matrix**:\n",
    "   - Let's create a small embedding matrix W of size (vocabulary_size × embedding_dimension)\n",
    "   - For our example, let's use embedding dimension = 2:\n",
    "     ```\n",
    "     W = [\n",
    "         [0.1, 0.2],  # cat\n",
    "         [0.3, 0.4],  # dog\n",
    "         [0.5, 0.6]   # bird\n",
    "     ]\n",
    "     ```\n",
    "\n",
    "3. **Matrix Multiplication**:\n",
    "   - The embedding operation is a matrix multiplication between the one-hot vector and the embedding matrix\n",
    "   - For the word \"cat\":\n",
    "     ```\n",
    "     [1, 0, 0] × [\n",
    "         [0.1, 0.2],\n",
    "         [0.3, 0.4],\n",
    "         [0.5, 0.6]\n",
    "     ] = [0.1, 0.2]\n",
    "     ```\n",
    "\n",
    "4. **Mathematical Formula**:\n",
    "   - Let's represent this formally:\n",
    "     ```\n",
    "     e = o × W\n",
    "     where:\n",
    "     e = embedding vector\n",
    "     o = one-hot vector\n",
    "     W = embedding matrix\n",
    "     ```\n",
    "\n",
    "5. **Numerical Example**:\n",
    "\n",
    "   a. One-hot vector for \"dog\":\n",
    "   ```\n",
    "   o = [0, 1, 0]\n",
    "   ```\n",
    "\n",
    "   b. Embedding matrix:\n",
    "   ```\n",
    "   W = [\n",
    "       [0.1, 0.2],  # cat\n",
    "       [0.3, 0.4],  # dog\n",
    "       [0.5, 0.6]   # bird\n",
    "   ]\n",
    "   ```\n",
    "\n",
    "   c. Matrix multiplication:\n",
    "   ```\n",
    "   e = o × W\n",
    "   e = [0, 1, 0] × [\n",
    "       [0.1, 0.2],\n",
    "       [0.3, 0.4],\n",
    "       [0.5, 0.6]\n",
    "   ]\n",
    "   ```\n",
    "\n",
    "   d. Calculating each element of the resulting vector:\n",
    "   ```\n",
    "   e[0] = (0 × 0.1) + (1 × 0.3) + (0 × 0.5) = 0.3\n",
    "   e[1] = (0 × 0.2) + (1 × 0.4) + (0 × 0.6) = 0.4\n",
    "   ```\n",
    "\n",
    "   e. Final embedding vector:\n",
    "   ```\n",
    "   e = [0.3, 0.4]\n",
    "   ```\n",
    "\n",
    "6. **Efficiency Trick**:\n",
    "   - In practice, it doesn't actually perform the matrix multiplication\n",
    "   - Since the one-hot vector has only one 1 and the rest are 0s\n",
    "   - It can simply select the corresponding row from the embedding matrix\n",
    "   - This is why embedding layers are so efficient\n",
    "\n",
    "\n",
    "7. **Learning Process**:\n",
    "   - During training, the values in the embedding matrix are updated\n",
    "   - The goal is to make similar words have similar vectors\n",
    "   - This is done through backpropagation and gradient descent\n",
    "   - The model learns to place words with similar meanings close to each other in this vector space\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "joblib.dump(embedded_docs, 'pickle/embedded_docs.joblib')\n",
    "model.save('pickle/model_embedding.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
